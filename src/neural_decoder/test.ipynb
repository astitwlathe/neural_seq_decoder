{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aslathe/miniconda3/envs/trans/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/aslathe/miniconda3/envs/trans:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       2_gnu    conda-forge\n",
      "aiohttp                   3.9.5                    pypi_0    pypi\n",
      "aiosignal                 1.3.1                    pypi_0    pypi\n",
      "alembic                   1.13.1                   pypi_0    pypi\n",
      "antlr4-python3-runtime    4.9.3                    pypi_0    pypi\n",
      "asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\n",
      "async-timeout             4.0.3                    pypi_0    pypi\n",
      "attrs                     23.2.0                   pypi_0    pypi\n",
      "autopage                  0.5.2                    pypi_0    pypi\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\n",
      "bzip2                     1.0.8                hd590300_5    conda-forge\n",
      "ca-certificates           2024.2.2             hbcca054_0    conda-forge\n",
      "click                     8.1.7                    pypi_0    pypi\n",
      "cliff                     4.6.0                    pypi_0    pypi\n",
      "cloudpickle               3.0.0                    pypi_0    pypi\n",
      "cmaes                     0.10.0                   pypi_0    pypi\n",
      "cmd2                      2.4.3                    pypi_0    pypi\n",
      "colorlog                  6.8.2                    pypi_0    pypi\n",
      "comm                      0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "debugpy                   1.8.1            py39h3d6467e_0    conda-forge\n",
      "decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\n",
      "distance                  0.1.3                    pypi_0    pypi\n",
      "edit-distance             1.0.6                    pypi_0    pypi\n",
      "executing                 2.0.1              pyhd8ed1ab_0    conda-forge\n",
      "frozenlist                1.4.1                    pypi_0    pypi\n",
      "fsspec                    2024.3.1                 pypi_0    pypi\n",
      "g2p-en                    2.1.0                    pypi_0    pypi\n",
      "greenlet                  3.0.3                    pypi_0    pypi\n",
      "hydra-core                1.3.2                    pypi_0    pypi\n",
      "hydra-optuna-sweeper      1.2.0                    pypi_0    pypi\n",
      "hydra-submitit-launcher   1.1.5                    pypi_0    pypi\n",
      "idna                      3.7                      pypi_0    pypi\n",
      "importlib-metadata        7.1.0              pyha770c72_0    conda-forge\n",
      "importlib_metadata        7.1.0                hd8ed1ab_0    conda-forge\n",
      "inflect                   7.2.1                    pypi_0    pypi\n",
      "ipykernel                 6.29.3             pyhd33586a_0    conda-forge\n",
      "ipython                   8.12.0             pyh41d4057_0    conda-forge\n",
      "jedi                      0.19.1             pyhd8ed1ab_0    conda-forge\n",
      "joblib                    1.4.0                    pypi_0    pypi\n",
      "jupyter_client            8.6.1              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_core              5.7.2            py39hf3d152e_0    conda-forge\n",
      "ld_impl_linux-64          2.40                 h55db66e_0    conda-forge\n",
      "libffi                    3.4.2                h7f98852_5    conda-forge\n",
      "libgcc-ng                 13.2.0               hc881cc4_6    conda-forge\n",
      "libgomp                   13.2.0               hc881cc4_6    conda-forge\n",
      "libnsl                    2.0.1                hd590300_0    conda-forge\n",
      "libsodium                 1.0.18               h36c2ea0_1    conda-forge\n",
      "libsqlite                 3.45.3               h2797004_0    conda-forge\n",
      "libstdcxx-ng              13.2.0               h95c4c6d_6    conda-forge\n",
      "libuuid                   2.38.1               h0b41bf4_0    conda-forge\n",
      "libxcrypt                 4.4.36               hd590300_1    conda-forge\n",
      "libzlib                   1.2.13               hd590300_5    conda-forge\n",
      "lightning                 2.2.3                    pypi_0    pypi\n",
      "lightning-utilities       0.11.2                   pypi_0    pypi\n",
      "llvmlite                  0.41.1                   pypi_0    pypi\n",
      "mako                      1.3.3                    pypi_0    pypi\n",
      "markupsafe                2.1.5                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.7              pyhd8ed1ab_0    conda-forge\n",
      "more-itertools            10.2.0                   pypi_0    pypi\n",
      "multidict                 6.0.5                    pypi_0    pypi\n",
      "ncurses                   6.4.20240210         h59595ed_0    conda-forge\n",
      "nest-asyncio              1.6.0              pyhd8ed1ab_0    conda-forge\n",
      "neural-decoder            0.0.1                    pypi_0    pypi\n",
      "nltk                      3.8.1                    pypi_0    pypi\n",
      "numba                     0.58.1                   pypi_0    pypi\n",
      "numpy                     1.25.0                   pypi_0    pypi\n",
      "nvidia-cublas-cu11        11.10.3.66               pypi_0    pypi\n",
      "nvidia-cuda-nvrtc-cu11    11.7.99                  pypi_0    pypi\n",
      "nvidia-cuda-runtime-cu11  11.7.99                  pypi_0    pypi\n",
      "nvidia-cudnn-cu11         8.5.0.96                 pypi_0    pypi\n",
      "omegaconf                 2.3.0                    pypi_0    pypi\n",
      "openssl                   3.2.1                hd590300_1    conda-forge\n",
      "optuna                    2.10.1                   pypi_0    pypi\n",
      "packaging                 24.0               pyhd8ed1ab_0    conda-forge\n",
      "parso                     0.8.4              pyhd8ed1ab_0    conda-forge\n",
      "pbr                       6.0.0                    pypi_0    pypi\n",
      "pexpect                   4.9.0              pyhd8ed1ab_0    conda-forge\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\n",
      "pip                       24.0               pyhd8ed1ab_0    conda-forge\n",
      "platformdirs              4.2.1              pyhd8ed1ab_0    conda-forge\n",
      "prettytable               3.10.0                   pypi_0    pypi\n",
      "prompt-toolkit            3.0.42             pyha770c72_0    conda-forge\n",
      "prompt_toolkit            3.0.42               hd8ed1ab_0    conda-forge\n",
      "psutil                    5.9.8            py39hd1e30aa_0    conda-forge\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\n",
      "pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "pygments                  2.17.2             pyhd8ed1ab_0    conda-forge\n",
      "pyperclip                 1.8.2                    pypi_0    pypi\n",
      "python                    3.9.19          h0755675_0_cpython    conda-forge\n",
      "python-dateutil           2.9.0              pyhd8ed1ab_0    conda-forge\n",
      "python_abi                3.9                      4_cp39    conda-forge\n",
      "pytorch-lightning         2.2.3                    pypi_0    pypi\n",
      "pyyaml                    6.0.1                    pypi_0    pypi\n",
      "pyzmq                     26.0.2           py39ha1047a2_0    conda-forge\n",
      "readline                  8.2                  h8228510_1    conda-forge\n",
      "regex                     2024.4.16                pypi_0    pypi\n",
      "scikit-learn              1.3.2                    pypi_0    pypi\n",
      "scipy                     1.11.1                   pypi_0    pypi\n",
      "setuptools                69.5.1             pyhd8ed1ab_0    conda-forge\n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\n",
      "sqlalchemy                2.0.29                   pypi_0    pypi\n",
      "sqlite                    3.45.3               h2c6b66d_0    conda-forge\n",
      "stack_data                0.6.2              pyhd8ed1ab_0    conda-forge\n",
      "stevedore                 5.2.0                    pypi_0    pypi\n",
      "submitit                  1.5.1                    pypi_0    pypi\n",
      "threadpoolctl             3.4.0                    pypi_0    pypi\n",
      "tk                        8.6.13          noxft_h4845f30_101    conda-forge\n",
      "torch                     1.13.1                   pypi_0    pypi\n",
      "torchmetrics              1.3.2                    pypi_0    pypi\n",
      "tornado                   6.4              py39hd1e30aa_0    conda-forge\n",
      "tqdm                      4.66.2                   pypi_0    pypi\n",
      "traitlets                 5.14.3             pyhd8ed1ab_0    conda-forge\n",
      "typeguard                 4.2.1                    pypi_0    pypi\n",
      "typing_extensions         4.11.0             pyha770c72_0    conda-forge\n",
      "tzdata                    2024a                h0c530f3_0    conda-forge\n",
      "wcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge\n",
      "wheel                     0.43.0             pyhd8ed1ab_1    conda-forge\n",
      "xz                        5.2.6                h166bdaf_0    conda-forge\n",
      "yarl                      1.9.4                    pypi_0    pypi\n",
      "zeromq                    4.3.5                h59595ed_1    conda-forge\n",
      "zipp                      3.18.1                   pypi_0    pypi\n",
      "zlib                      1.2.13               hd590300_5    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version    Editable project location\n",
      "------------------------ ---------- --------------------------------------------------------------------------------------\n",
      "aiohttp                  3.9.5\n",
      "aiosignal                1.3.1\n",
      "alembic                  1.13.1\n",
      "antlr4-python3-runtime   4.9.3\n",
      "asttokens                2.4.1\n",
      "async-timeout            4.0.3\n",
      "attrs                    23.2.0\n",
      "autopage                 0.5.2\n",
      "backcall                 0.2.0\n",
      "click                    8.1.7\n",
      "cliff                    4.6.0\n",
      "cloudpickle              3.0.0\n",
      "cmaes                    0.10.0\n",
      "cmd2                     2.4.3\n",
      "colorlog                 6.8.2\n",
      "comm                     0.2.2\n",
      "debugpy                  1.8.1\n",
      "decorator                5.1.1\n",
      "Distance                 0.1.3\n",
      "edit-distance            1.0.6\n",
      "executing                2.0.1\n",
      "frozenlist               1.4.1\n",
      "fsspec                   2024.3.1\n",
      "g2p-en                   2.1.0\n",
      "greenlet                 3.0.3\n",
      "hydra-core               1.3.2\n",
      "hydra-optuna-sweeper     1.2.0\n",
      "hydra-submitit-launcher  1.1.5\n",
      "idna                     3.7\n",
      "importlib_metadata       7.1.0\n",
      "inflect                  7.2.1\n",
      "ipykernel                6.29.3\n",
      "ipython                  8.12.0\n",
      "jedi                     0.19.1\n",
      "joblib                   1.4.0\n",
      "jupyter_client           8.6.1\n",
      "jupyter_core             5.7.2\n",
      "lightning                2.2.3\n",
      "lightning-utilities      0.11.2\n",
      "llvmlite                 0.41.1\n",
      "Mako                     1.3.3\n",
      "MarkupSafe               2.1.5\n",
      "matplotlib-inline        0.1.7\n",
      "more-itertools           10.2.0\n",
      "multidict                6.0.5\n",
      "nest_asyncio             1.6.0\n",
      "neural_decoder           0.0.1      /home/aslathe/Miscellaneous/aslathe/SpeechBMI/practice/comp_project/neural_seq_decoder\n",
      "nltk                     3.8.1\n",
      "numba                    0.58.1\n",
      "numpy                    1.25.0\n",
      "nvidia-cublas-cu11       11.10.3.66\n",
      "nvidia-cuda-nvrtc-cu11   11.7.99\n",
      "nvidia-cuda-runtime-cu11 11.7.99\n",
      "nvidia-cudnn-cu11        8.5.0.96\n",
      "omegaconf                2.3.0\n",
      "optuna                   2.10.1\n",
      "packaging                24.0\n",
      "parso                    0.8.4\n",
      "pbr                      6.0.0\n",
      "pexpect                  4.9.0\n",
      "pickleshare              0.7.5\n",
      "pip                      24.0\n",
      "platformdirs             4.2.1\n",
      "prettytable              3.10.0\n",
      "prompt-toolkit           3.0.42\n",
      "psutil                   5.9.8\n",
      "ptyprocess               0.7.0\n",
      "pure-eval                0.2.2\n",
      "Pygments                 2.17.2\n",
      "pyperclip                1.8.2\n",
      "python-dateutil          2.9.0\n",
      "pytorch-lightning        2.2.3\n",
      "PyYAML                   6.0.1\n",
      "pyzmq                    26.0.2\n",
      "regex                    2024.4.16\n",
      "scikit-learn             1.3.2\n",
      "scipy                    1.11.1\n",
      "setuptools               69.5.1\n",
      "six                      1.16.0\n",
      "SQLAlchemy               2.0.29\n",
      "stack-data               0.6.2\n",
      "stevedore                5.2.0\n",
      "submitit                 1.5.1\n",
      "threadpoolctl            3.4.0\n",
      "torch                    1.13.1\n",
      "torchmetrics             1.3.2\n",
      "tornado                  6.4\n",
      "tqdm                     4.66.2\n",
      "traitlets                5.14.3\n",
      "typeguard                4.2.1\n",
      "typing_extensions        4.11.0\n",
      "wcwidth                  0.2.13\n",
      "wheel                    0.43.0\n",
      "yarl                     1.9.4\n",
      "zipp                     3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "range(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "\n",
      "Returns a 1-D tensor of size :math:`\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1`\n",
      "with values from :attr:`start` to :attr:`end` with step :attr:`step`. Step is\n",
      "the gap between two values in the tensor.\n",
      "\n",
      ".. math::\n",
      "    \\text{out}_{i+1} = \\text{out}_i + \\text{step}.\n",
      "\n",
      ".. warning::\n",
      "    This function is deprecated and will be removed in a future release because its behavior is inconsistent with\n",
      "    Python's range builtin. Instead, use :func:`torch.arange`, which produces values in [start, end).\n",
      "\n",
      "Args:\n",
      "    start (float): the starting value for the set of points. Default: ``0``.\n",
      "    end (float): the ending value for the set of points\n",
      "    step (float): the gap between each pair of adjacent points. Default: ``1``.\n",
      "\n",
      "Keyword args:\n",
      "    out (Tensor, optional): the output tensor.\n",
      "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`). If `dtype` is not given, infer the data type from the other input\n",
      "        arguments. If any of `start`, `end`, or `stop` are floating-point, the\n",
      "        `dtype` is inferred to be the default dtype, see\n",
      "        :meth:`~torch.get_default_dtype`. Otherwise, the `dtype` is inferred to\n",
      "        be `torch.int64`.\n",
      "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "        Default: ``torch.strided``.\n",
      "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "        Default: if ``None``, uses the current device for the default tensor type\n",
      "        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "    requires_grad (bool, optional): If autograd should record operations on the\n",
      "        returned tensor. Default: ``False``.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> torch.range(1, 4)\n",
      "    tensor([ 1.,  2.,  3.,  4.])\n",
      "    >>> torch.range(1, 4, 0.5)\n",
      "    tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "?torch.range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Extracts sliding local blocks from a batched input tensor.\n",
      "\n",
      "Consider a batched :attr:`input` tensor of shape :math:`(N, C, *)`,\n",
      "where :math:`N` is the batch dimension, :math:`C` is the channel dimension,\n",
      "and :math:`*` represent arbitrary spatial dimensions. This operation flattens\n",
      "each sliding :attr:`kernel_size`-sized block within the spatial dimensions\n",
      "of :attr:`input` into a column (i.e., last dimension) of a 3-D :attr:`output`\n",
      "tensor of shape :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)`, where\n",
      ":math:`C \\times \\prod(\\text{kernel\\_size})` is the total number of values\n",
      "within each block (a block has :math:`\\prod(\\text{kernel\\_size})` spatial\n",
      "locations each containing a :math:`C`-channeled vector), and :math:`L` is\n",
      "the total number of such blocks:\n",
      "\n",
      ".. math::\n",
      "    L = \\prod_d \\left\\lfloor\\frac{\\text{spatial\\_size}[d] + 2 \\times \\text{padding}[d] %\n",
      "        - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) - 1}{\\text{stride}[d]} + 1\\right\\rfloor,\n",
      "\n",
      "where :math:`\\text{spatial\\_size}` is formed by the spatial dimensions\n",
      "of :attr:`input` (:math:`*` above), and :math:`d` is over all spatial\n",
      "dimensions.\n",
      "\n",
      "Therefore, indexing :attr:`output` at the last dimension (column dimension)\n",
      "gives all values within a certain block.\n",
      "\n",
      "The :attr:`padding`, :attr:`stride` and :attr:`dilation` arguments specify\n",
      "how the sliding blocks are retrieved.\n",
      "\n",
      "* :attr:`stride` controls the stride for the sliding blocks.\n",
      "\n",
      "* :attr:`padding` controls the amount of implicit zero-paddings on both\n",
      "  sides for :attr:`padding` number of points for each dimension before\n",
      "  reshaping.\n",
      "\n",
      "* :attr:`dilation` controls the spacing between the kernel points; also known as the à trous algorithm.\n",
      "  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n",
      "\n",
      "Args:\n",
      "    kernel_size (int or tuple): the size of the sliding blocks\n",
      "    stride (int or tuple, optional): the stride of the sliding blocks in the input\n",
      "                                     spatial dimensions. Default: 1\n",
      "    padding (int or tuple, optional): implicit zero padding to be added on\n",
      "                                      both sides of input. Default: 0\n",
      "    dilation (int or tuple, optional): a parameter that controls the\n",
      "                                       stride of elements within the\n",
      "                                       neighborhood. Default: 1\n",
      "\n",
      "* If :attr:`kernel_size`, :attr:`dilation`, :attr:`padding` or\n",
      "  :attr:`stride` is an int or a tuple of length 1, their values will be\n",
      "  replicated across all spatial dimensions.\n",
      "\n",
      "* For the case of two input spatial dimensions this operation is sometimes\n",
      "  called ``im2col``.\n",
      "\n",
      ".. note::\n",
      "    :class:`~torch.nn.Fold` calculates each combined value in the resulting\n",
      "    large tensor by summing all values from all containing blocks.\n",
      "    :class:`~torch.nn.Unfold` extracts the values in the local blocks by\n",
      "    copying from the large tensor. So, if the blocks overlap, they are not\n",
      "    inverses of each other.\n",
      "\n",
      "    In general, folding and unfolding operations are related as\n",
      "    follows. Consider :class:`~torch.nn.Fold` and\n",
      "    :class:`~torch.nn.Unfold` instances created with the same\n",
      "    parameters:\n",
      "\n",
      "    >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...)\n",
      "    >>> fold = nn.Fold(output_size=..., **fold_params)\n",
      "    >>> unfold = nn.Unfold(**fold_params)\n",
      "\n",
      "    Then for any (supported) ``input`` tensor the following\n",
      "    equality holds:\n",
      "\n",
      "    ::\n",
      "\n",
      "        fold(unfold(input)) == divisor * input\n",
      "\n",
      "    where ``divisor`` is a tensor that depends only on the shape\n",
      "    and dtype of the ``input``:\n",
      "\n",
      "    >>> # xdoctest: +SKIP\n",
      "    >>> input_ones = torch.ones(input.shape, dtype=input.dtype)\n",
      "    >>> divisor = fold(unfold(input_ones))\n",
      "\n",
      "    When the ``divisor`` tensor contains no zero elements, then\n",
      "    ``fold`` and ``unfold`` operations are inverses of each\n",
      "    other (up to constant divisor).\n",
      "\n",
      ".. warning::\n",
      "    Currently, only 4-D input tensors (batched image-like tensors) are\n",
      "    supported.\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(N, C, *)`\n",
      "    - Output: :math:`(N, C \\times \\prod(\\text{kernel\\_size}), L)` as described above\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> unfold = nn.Unfold(kernel_size=(2, 3))\n",
      "    >>> input = torch.randn(2, 5, 3, 4)\n",
      "    >>> output = unfold(input)\n",
      "    >>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n",
      "    >>> # 4 blocks (2x3 kernels) in total in the 3x4 input\n",
      "    >>> output.size()\n",
      "    torch.Size([2, 30, 4])\n",
      "\n",
      "    >>> # xdoctest: +IGNORE_WANT\n",
      "    >>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
      "    >>> inp = torch.randn(1, 3, 10, 12)\n",
      "    >>> w = torch.randn(2, 3, 4, 5)\n",
      "    >>> inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
      "    >>> out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
      "    >>> out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))\n",
      "    >>> # or equivalently (and avoiding a copy),\n",
      "    >>> # out = out_unf.view(1, 2, 7, 8)\n",
      "    >>> (torch.nn.functional.conv2d(inp, w) - out).abs().max()\n",
      "    tensor(1.9073e-06)\n",
      "\n",
      ".. _link:\n",
      "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/trans/lib/python3.9/site-packages/torch/nn/modules/fold.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?torch.nn.Unfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelLen = 2\n",
    "strideLen = 2\n",
    "\n",
    "unfold = torch.nn.Unfold(\n",
    "      (kernelLen, 2), dilation=1, padding=0, stride=strideLen\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4243, -0.0889,  0.1105,  0.5781],\n",
       "          [ 0.5646,  0.6328, -0.6676, -0.2404],\n",
       "          [-1.0368, -0.7414, -1.5139, -0.7120],\n",
       "          [ 0.2834,  1.2130, -0.4301, -0.4276]],\n",
       "\n",
       "         [[-0.4364, -0.3487,  1.5730,  0.3304],\n",
       "          [ 2.4208,  1.2818,  0.0965,  0.8640],\n",
       "          [-0.0843,  0.8428,  0.8863,  1.8264],\n",
       "          [ 2.0930, -1.1422, -0.8997, -2.4316]],\n",
       "\n",
       "         [[-0.7015,  0.5208,  0.0760, -0.4462],\n",
       "          [-0.7199,  0.1263,  0.7531,  1.0753],\n",
       "          [ 0.2008, -0.8448, -0.6156,  2.3365],\n",
       "          [-0.5070,  2.0409, -1.0786,  1.5215]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4734, -0.0469,  0.4908, -0.7120],\n",
       "          [ 1.3643,  1.0044, -0.8080, -0.2376],\n",
       "          [-0.2465, -1.0777, -0.1625, -2.5030],\n",
       "          [-2.2419,  0.2258,  0.9252, -0.4425]],\n",
       "\n",
       "         [[-2.0225, -0.3422, -0.8556, -0.5615],\n",
       "          [ 1.1729, -0.5579, -0.5250, -1.6069],\n",
       "          [-1.1784,  0.4389,  0.2545,  1.1521],\n",
       "          [-0.2727,  0.2224, -1.9484, -0.5063]],\n",
       "\n",
       "         [[ 1.3981, -0.3629, -0.8983,  0.5627],\n",
       "          [-1.3034, -1.1041,  0.3555,  1.1933],\n",
       "          [-1.0320, -1.0047,  0.5264,  1.5632],\n",
       "          [ 1.5167,  1.2477, -0.9166, -0.1223]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vals = torch.randn(2, 3, 4, 4)\n",
    "input_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4243,  0.1105, -1.0368, -1.5139],\n",
       "         [-0.0889,  0.5781, -0.7414, -0.7120],\n",
       "         [ 0.5646, -0.6676,  0.2834, -0.4301],\n",
       "         [ 0.6328, -0.2404,  1.2130, -0.4276],\n",
       "         [-0.4364,  1.5730, -0.0843,  0.8863],\n",
       "         [-0.3487,  0.3304,  0.8428,  1.8264],\n",
       "         [ 2.4208,  0.0965,  2.0930, -0.8997],\n",
       "         [ 1.2818,  0.8640, -1.1422, -2.4316],\n",
       "         [-0.7015,  0.0760,  0.2008, -0.6156],\n",
       "         [ 0.5208, -0.4462, -0.8448,  2.3365],\n",
       "         [-0.7199,  0.7531, -0.5070, -1.0786],\n",
       "         [ 0.1263,  1.0753,  2.0409,  1.5215]],\n",
       "\n",
       "        [[ 0.4734,  0.4908, -0.2465, -0.1625],\n",
       "         [-0.0469, -0.7120, -1.0777, -2.5030],\n",
       "         [ 1.3643, -0.8080, -2.2419,  0.9252],\n",
       "         [ 1.0044, -0.2376,  0.2258, -0.4425],\n",
       "         [-2.0225, -0.8556, -1.1784,  0.2545],\n",
       "         [-0.3422, -0.5615,  0.4389,  1.1521],\n",
       "         [ 1.1729, -0.5250, -0.2727, -1.9484],\n",
       "         [-0.5579, -1.6069,  0.2224, -0.5063],\n",
       "         [ 1.3981, -0.8983, -1.0320,  0.5264],\n",
       "         [-0.3629,  0.5627, -1.0047,  1.5632],\n",
       "         [-1.3034,  0.3555,  1.5167, -0.9166],\n",
       "         [-1.1041,  1.1933,  1.2477, -0.1223]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfold(input_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfold(input_vals).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: gru.weight_ih_l0, Shape: torch.Size([60, 10])\n",
      "Parameter: gru.weight_hh_l0, Shape: torch.Size([60, 20])\n",
      "Parameter: gru.bias_ih_l0, Shape: torch.Size([60])\n",
      "Parameter: gru.bias_hh_l0, Shape: torch.Size([60])\n",
      "Parameter: gru.weight_ih_l1, Shape: torch.Size([60, 20])\n",
      "Parameter: gru.weight_hh_l1, Shape: torch.Size([60, 20])\n",
      "Parameter: gru.bias_ih_l1, Shape: torch.Size([60])\n",
      "Parameter: gru.bias_hh_l1, Shape: torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a GRU decoder module\n",
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(GRUDecoder, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.gru(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the GRU decoder\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "gru_decoder = GRUDecoder(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Get named parameters and print their names and shapes\n",
    "for name, param in gru_decoder.named_parameters():\n",
    "    print(f\"Parameter: {name}, Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUDecoder(\n",
      "  (gru): GRU(10, 20, num_layers=2, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gru_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([20, 10])\n",
      "0.bias torch.Size([20])\n",
      "2.weight torch.Size([5, 20])\n",
      "2.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 5)\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Name: fc1.weight, Parameter Shape: torch.Size([5, 10])\n",
      "Parameter Name: fc1.bias, Parameter Shape: torch.Size([5])\n",
      "Parameter Name: fc2.weight, Parameter Shape: torch.Size([2, 5])\n",
      "Parameter Name: fc2.bias, Parameter Shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Access named parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter Name: {name}, Parameter Shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = str(dir(param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
